import nltk
nltk.download('punkt_tab')
import random
import json
import pickle
import numpy as np
import tensorflow as tf
import nltk
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('wordnet')
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.optimizers import SGD

lemmatizer= WordNetLemmatizer()
intents = json.load(open('/content/intents.json'))
words=[]
classes=[]
documents=[]
ignoreLetters=['?','!','.',',']
for i in intents['intents']:
  for pattern in i['patterns']:
    # Download the 'punkt_tab' data if not already present
    
    wordList = nltk.word_tokenize(pattern)
    words.extend(wordList)
    documents.append((wordList,i['tag']))
    if i['tag'] not in classes:
      classes.append(i['tag'])
words=[lemmatizer.lemmatize(i) for i in words if i not in ignoreLetters]
words=sorted(set(words))
classes=sorted(set(classes))
pickle.dump(words,open('words.pkl','wb'))
pickle.dump(classes,open('classes.pkl','wb'))

training =[]
outputEmpty=[0]*len(classes)
for document in documents:
  bag=[]
  wordPatterns=document[0]
  wordPatterns=[lemmatizer.lemmatize(word.lower()) for word in wordPatterns]
  for word in words:
    bag.append(1) if word in wordPatterns else bag.append(0)

  outputRow = list(outputEmpty)
  outputRow[classes.index(document[1])]=1
  training.append(bag + outputRow)

random.shuffle(training)
training=np.array(training)

trainx=training[:,:len(words)]
trainy=training[:,len(words):]

model = tf.keras.Sequential()

model.add(tf.keras.layers.Dense(128, input_shape=(len(trainx[0]),),activation = 'relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(64,activation = 'relu'))
model.add(tf.keras.layers.Dense(len(trainy[0]),activation = 'softmax'))

sgd=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9,nesterov=True)
model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])

hist= model.fit(np.array(trainx),np.array(trainy),epochs=200,batch_size=5,verbose=1)
model.save('chatbotmodel.h5',hist)
print('Done')

import random
import json
import pickle
import numpy as np
import nltk
import datetime
from nltk.stem import WordNetLemmatizer
from tensorflow.keras.models import load_model
lemmatizer= WordNetLemmatizer()
intents = json.load(open('/content/intents.json'))
words = pickle.load(open('words.pkl','rb'))
classes = pickle.load(open('classes.pkl','rb'))
model = load_model('chatbotmodel.h5')

def cleanupsentence(sentence):
  sentenceWords = nltk.word_tokenize(sentence)
  sentenceWords = [lemmatizer.lemmatize(word) for word in sentenceWords]
  return sentenceWords

def bagofwords(sentence):
  sentenceWords = cleanupsentence(sentence)
  bag = [0]*len(words)
  for w in sentenceWords:
    for i,word in enumerate(words):
      if word == w:
        bag[i]=1
  return np.array(bag)

def predictclass(sentence):
  bow = bagofwords(sentence)
  res = model.predict(np.array([bow]))[0]

  ERRORTHRESHOLD = 0.25
  results = [[i,r] for i,r in enumerate(res) if r > ERRORTHRESHOLD]
  results.sort(key=lambda x:x[1],reverse=True)

  returnList = []
  for r in results:
    returnList.append({'intent':classes[r[0]],'probability':str(r[1])})
  return returnList

def getresponse(intentslist,intentsjson):

  listofintents = intentsjson['intents']
  tag = intentslist[0]['intent']
  if tag == "datetime":
        current_date = datetime.date.today().strftime("%Y-%m-%d")  # Format date as Year-Month-Day
        current_time = datetime.datetime.now().strftime("%H:%M:%S")  # Format time as Hour:Minute:Second
        return f"Today's date is {current_date} and the current time is {current_time}"
  for i in listofintents:
    if i['tag'] == tag:
      result = random.choice(i['responses'])
      break
  return result

print('Bot is running')
while True:
  message = input('')
  ints = predictclass(message)

  if message in ['quit', 'Quit','Exit', 'exit','shutdown', 'Shutdown','bye','good bye' ]:
    print('Bot is shutting down')
    break
  else:
    res = getresponse(ints,intents)

    print(res)
